const QUESTIONS = [
  {
    "id": 1,
    "chapter": 1,
    "chapterName": "人工知能（AI）とは",
    "question": "第1次AIブーム（1950年代後半〜1960年代）の中心技術として最も適切なものはどれか。",
    "choices": ["知識表現とエキスパートシステム", "推論と探索", "機械学習とディープラーニング", "生成AIと大規模言語モデル"],
    "correct": [1],
    "explanation": "第1次AIブームでは「推論・探索」が中心技術でした。迷路問題やパズルの解法が研究されましたが、トイ・プロブレム（簡略化された問題）しか解けないという限界がありました。"
  },
  {
    "id": 2,
    "chapter": 1,
    "chapterName": "人工知能（AI）とは",
    "question": "「AIが新たな成果を達成すると、その原理が解明された瞬間に『それは真の知能ではない』と見なされる心理現象」を何と呼ぶか。",
    "choices": ["フレーム問題", "シンボルグラウンディング問題", "AI効果", "中国語の部屋"],
    "correct": [2],
    "explanation": "AI効果とは、AIが何かを達成しても「それは本当の知能ではない」と評価が変わる現象です。チェスや将棋AIでも見られました。"
  },
  {
    "id": 3,
    "chapter": 6,
    "chapterName": "生成AI",
    "question": "LLM（大規模言語モデル）が事実と異なる情報をもっともらしく生成する現象を何と呼ぶか。",
    "choices": ["過学習", "バイアス", "ハルシネーション", "ドリフト"],
    "correct": [2],
    "explanation": "ハルシネーション（Hallucination）は、LLMが事実に基づかない情報をもっともらしく生成してしまう現象です。LLMの重要な課題の一つです。"
  },
  {
    "id": 4,
    "chapter": 3,
    "chapterName": "機械学習の具体的手法",
    "question": "モデルを学習する過程で、適切なパラメータの調整が行われないとどのような問題が生じる可能性があるか、次の選択肢から正しいものを全て選べ。",
    "choices": ["実行ごとに結果が変化してしまう", "モデルが未知のデータに対して一般化できない", "学習が不安定になり結果が不規則", "プログラムが異常終了しやすくなる", "AIを利用活用する場合はBPRは必須となる"],
    "correct": [1, 2],
    "explanation": "選択肢2: モデルが未知のデータに対して一般化できない、選択肢3: 学習が不安定になり結果が不規則が正解です。適切なパラメータ調整が行われないと、過学習や学習の不安定化が起こります。"
  },
  {
    "id": 5,
    "chapter": 9,
    "chapterName": "AI法律・倫理・社会問題",
    "question": "EU AI規制法（AI Act）で採用されているアプローチはどれか。",
    "choices": ["すべてのAIを一律に規制する", "リスクベースのアプローチで段階的に規制する", "AI開発を全面的に禁止する", "企業の自主規制に完全に委ねる"],
    "correct": [1],
    "explanation": "EU AI規制法はリスクベースのアプローチを採用し、許容できないリスク（禁止）、ハイリスク（厳格な要件）、限定リスク（透明性義務）、最小リスク（規制なし）の4段階で規制します。"
  }
];
